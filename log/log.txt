#코로나때는 항공유가 싸서 항공유를 썼음 -> 타겟값이 낮아짐 -> 일별 항공유 가격 데이터를 쓰면 어떰?

02-14
 1. preprocessing : 년/월/일/시간
 2. EDA : 주기 발견
   -> 주기 활용 고민, 이상치 처리 생각(ex, 3sigma)
 3. F.E : kalman, moving average, log 사용해보았는데 MAE 값 차이 X
   -> LG 공정에서 item별 측정오차나 이런걸 생각해서 분산을 줄여주려고 그때 사용했었는데 결과가 좋았어서 먼저 사용해보았음.

02-15
 1. preprocessing : train 07시 이후를 다 날리고 07시 이전시간을 평균이나 합같은 통계량으로 활용해보자,
   -> 왜? : 07시가 아닌 시간대의 target은 interpolate로 보간되었기 때문
 2. corr 상위 5개만 썻는데 pycaret catboost 9.9까지는 뽑힘(NO F.E), FE 적용시키니까 11
 3. 모든 피처 살리고 3시그마 적용 후 LR -> 9.83, 피처 10개로 LR -> 9.7
 4. 3시그마 + 피처 10개, pycaret으로 best_model(et) -> 8.7
 5. 3시그마 + 피처 10개 + F.E + pycaret_LR -> 7.9, ridge -> 7.8, gbr -> 7.6(tune_model -> 6.12)
 6. 3시그마 + 피처 10개 + NO F.E + pycaret best_model(cat) no tune -> 6.64, gbr no tune -> 6.1, tune ->7.48, et(notune) ->6.63(train, test 7시만 필터링)
 7. 6에서 했던 피처 + catboost_optuna -> 4.6 나오는데 왜 실제로는 7이 나오지?
 8. 6에서 했던 피처 + optuna 구조 변경, score print추가로 5.5까지 뽑음

02-16
 스무딩기법이니까, 7시만 데이터쓰는걸로 필터링 먼저 하지 말고 먼저 F.E한다음에 7시로 필터링을 해보자
 + Tabnet을 써보자
 1. NO.FE Tabnet -> 5점대까지 뽑힘

02-17
 1. orange 미팅을 통해 내 코드를 모듈화로 바꾸는 작업(시간 꽤 소요)
 2. 피처 몇개만 뽑아서 선형회귀(왜 안되지)
  -> 그냥 가중치를 바꿔준거라 생각하고 내가 직접 선형모델 구현


02-20
 1.  Domain 공부
 2. '+' 상관관계 애들만 써서 TabNet 돌리면 4점대 나오긴함(train 다씀)
 3. 21,22,23 인 애들만 따로따로 돌려봄 성능 x
 4. TI, PI, FI인 애들만 따로따로 돌려봄 TI가 제일 잘나옴    -> 온도여서 그런거같은데
 5. IC인 애들만 따로따로 돌려봄 성능 x
 6. Feed인 애들만 따로 돌려봄 성능 x


02-21
  1. train 데이터셋에서 약33000 이후 데이터들 날림(이상치로 판단)
    -> 다른 데이터셋들과 다르게 타겟값이 피처들의 분포를 따라가지않음
    -> 타겟값은 손으로 직접 측정한 값이기 때문에 이상치라 판단

02-22
  1. Llinear Regressor 커스텀 해봄(residual fitting)
    -> 너무 노가다인거같음
  2. PCA, VIF 시도
    -> 별로임


 02-23
   1. 마지막 잔차 DNN
TI23502(D/O Vapor T)

TI23120